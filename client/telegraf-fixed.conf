[agent]
  debug = false
  hostname = "${DOCKER_HOST}"
  interval = "10s"
  round_interval = true
  skip_processors_after_aggregators = true

[[inputs.conntrack]]

# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
  report_active = false
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false
  # fieldexclude = ["time_*"]

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs"]

[[inputs.diskio]]
  devices = ["sd*", "nvme*"]
  device_tags = ["ID_TYPE", "ID_FS_TYPE", "ID_FS_LABEL"]
  fieldexclude = ['read_time', 'io_time', 'iops_in_progress', 'merged_reads', 'weighted_io_time', 'merged_writes', 'reads', 'writes', 'read_bytes', 'write_bytes']
  skip_serial_number = true

# Read metrics about docker containers
[[inputs.docker]]
  ## Docker Endpoint
  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
  endpoint = "unix://${DOCKER_SOCKET}"

  ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)
  ## Note: configure this in one of the manager nodes in a Swarm cluster.
  ## configuring in multiple Swarm managers results in duplication of metrics.
  gather_services = false

  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars
  source_tag = false

  ## Containers to include and exclude. Collect all if empty. Globs accepted.
  container_name_include = []
  container_name_exclude = []

  ## Container states to include and exclude. Globs accepted.
  ## When empty only containers in the "running" state will be captured.
  ## example: container_state_include = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
  ## example: container_state_exclude = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
  container_state_include = ["running"]
  container_state_exclude = []

  ## Objects to include for disk usage query
  ## Allowed values are "container", "image", "volume"
  ## When empty disk usage is excluded
  storage_objects = ["container", "volume"]

  ## Timeout for docker list, info, and stats commands
  timeout = "5s"

  ## Specifies for which classes a per-device metric should be issued
  ## Possible values are 'cpu' (cpu0, cpu1, ...), 'blkio' (8:0, 8:1, ...) and 'network' (eth0, eth1, ...)
  ## Please note that this setting has no effect if 'perdevice' is set to 'true'
  perdevice_include = ["cpu", "blkio", "network"]

  ## Specifies for which classes a total metric should be issued. Total is an aggregated of the 'perdevice' values.
  ## Possible values are 'cpu', 'blkio' and 'network'
  ## Total 'cpu' is reported directly by Docker daemon, and 'network' and 'blkio' totals are aggregated by this plugin.
  ## Please note that this setting has no effect if 'total' is set to 'false'
  total_include = ["cpu", "blkio", "network"]

  ## Docker labels to include and exclude as tags. Globs accepted.
  ## Note that an empty array for both will include all labels as tags
  docker_label_include = []
  docker_label_exclude = ["*"]

  ## Which environment variables should we use as a tag
  # tag_env = ["JAVA_HOME", "HEAP_SIZE"]

  ## Optional TLS Config
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false

# Read metrics from one or more commands that can output to stdout
[[inputs.exec]]
  ## Commands array
  commands = ["/check-reboot.sh"]

  ## Environment variables
  ## Array of "key=value" pairs to pass as environment variables
  ## e.g. "KEY=value", "USERNAME=John Doe",
  ## "LD_LIBRARY_PATH=/opt/custom/lib64:/usr/local/libs"
  # environment = []

  ## Timeout for each command to complete.
  timeout = "5s"

  ## Measurement name suffix
  ## Used for separating different commands
  name_suffix = "_custom"

  ## Ignore Error Code
  ## If set to true, a non-zero error code in not considered an error and the
  ## plugin will continue to parse the output.
  ignore_error = false

  ## Data format
  ## By default, exec expects JSON. This was done for historical reasons and is
  ## different than other inputs that use the influx line protocol. Each data
  ## format has its own unique set of configuration options, read more about
  ## them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
  data_format = "influx"

[[inputs.internal]]

[[inputs.interrupts]]

[[inputs.kernel]]

[[inputs.linux_sysctl_fs]]

[[inputs.mem]]

[[inputs.net]]
  ignore_protocol_stats = true

[[inputs.netstat]]

[[inputs.nstat]]
  dump_zeros = true

[[inputs.processes]]

[[inputs.swap]]

# Read metrics about system load & uptime
[[inputs.system]]
  # no configuration

# [[outputs.http]]
#   alias = "prometheus-remote-write"
#   url = "http://${AGENT_HOST}:${AGENT_PORT}/api/v1/write"
#   insecure_skip_verify = true

#   data_format = "prometheusremotewrite"
#   timeout = "10s"

#   [outputs.http.headers]
#     Content-Encoding = "snappy"
#     Content-Type = "application/x-protobuf"
#     X-Prometheus-Remote-Write-Version = "2.0.0"

[[outputs.influxdb]]
  urls = ["http://peeper-agent:8429"] # <-- УБРАЛИ /write ИЗ URL
  database = "telegraf" # <-- Можно указать, vmagent это проигнорирует, но это хорошая практика
  skip_database_creation = true
  timeout = "30s"
